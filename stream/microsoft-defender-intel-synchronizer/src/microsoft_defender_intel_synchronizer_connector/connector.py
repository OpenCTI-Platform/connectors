import json
import sys
import time
from datetime import datetime, timedelta, timezone

from pycti import OpenCTIConnectorHelper

from .api_handler import DefenderApiHandler
from .config_variables import ConfigConnector
from .utils import (
    FILE_HASH_TYPES_MAPPER,
)


def chunker_list(a, n):
    """
    Split a list into chunks of size n.
    :param a: List to be split
    :param n: Size of each chunk
    :return: List of chunks
    """
    return [a[i : i + n] for i in range(0, len(a), n)]


class MicrosoftDefenderIntelSynchronizerConnector:
    """
    Specifications of the Stream connector

    This class encapsulates the main actions, expected to be run by any stream connector.
    Note that the attributes defined below will be complemented per each connector type.
    This type of connector has the capability to listen to live streams from the OpenCTI platform.
    It is highly useful for creating connectors that can react and make decisions in real time.
    Actions on OpenCTI will apply the changes to the third-party connected platform
    ---

    Attributes
        - `config (ConfigConnector())`:
            Initialize the connector with necessary configuration environment variables

        - `helper (OpenCTIConnectorHelper(config))`:
            This is the helper to use.
            ALL connectors have to instantiate the connector helper with configurations.
            Doing this will do a lot of operations behind the scene.

    ---

    Best practices
        - `self.helper.connector_logger.[info/debug/warning/error]` is used when logging a message

    """

    def __init__(self):
        """
        Initialize the Connector with necessary configurations
        """

        # Load configuration file and connection helper
        self.config = ConfigConnector()
        self.helper = self.config.helper
        self.api = DefenderApiHandler(self.helper, self.config)

    def _convert_indicator_to_observables(self, data) -> list[dict]:
        """
        Convert an OpenCTI indicator to its corresponding observables.
        Observables taken into account:
        :param data: OpenCTI indicator data
        :return: Observables data
        """
        try:
            observables = []
            parsed_observables = self.helper.get_attribute_in_extension(
                "observable_values", data
            )
            if parsed_observables:
                # Iterate over the parsed observables
                for observable in parsed_observables:
                    observable_data = {}
                    observable_data.update(data)
                    x_opencti_observable_type = observable.get("type").lower()
                    if x_opencti_observable_type != "stixfile":
                        observable_data["type"] = x_opencti_observable_type
                        observable_data["value"] = observable.get("value")
                        observables.append(observable_data)
                    else:
                        file = {}
                        for key, value in observable.get("hashes", {}).items():
                            hash_type = FILE_HASH_TYPES_MAPPER.get(key.lower())
                            if hash_type is not None:
                                file[hash_type] = value
                        if file:
                            observable_data["type"] = "file"
                            observable_data["hashes"] = file
                            observables.append(observable_data)

            return observables
        except Exception:
            indicator_opencti_id = OpenCTIConnectorHelper.get_attribute_in_extension(
                "id", data
            )
            self.helper.connector_logger.warning(
                "[CREATE] Cannot convert STIX indicator { " + indicator_opencti_id + "}"
            )

    INDICATOR_QUERY = """
    query Indicators(
    $filters: FilterGroup,
    $first: Int,
    $after: ID,
    $orderBy: IndicatorsOrdering,
    $orderMode: OrderingMode
    ) {
    indicators(
        filters: $filters,
        first: $first,
        after: $after,
        orderBy: $orderBy,
        orderMode: $orderMode
    ) {
        edges {
        node {
            id
            standard_id
            created
            modified
            confidence
            x_opencti_score
            toStix
        }
        }
        pageInfo {
        globalCount
        endCursor
        hasNextPage
        }
    }
    }
    """

    def fetch_indicators_batched(
        self, filters, max_size=15000, batch_size=500, collection_name=None
    ):
        """
        Fetch indicators in batches using cursor-based pagination, stopping at the end of the collection or max_size.
        Logs each batch request for debugging, including the collection name if provided.
        """
        indicators = []
        after = None
        total_fetched = 0
        batch_num = 1
        collection_str = (
            f" for collection '{collection_name}'" if collection_name else ""
        )
        while total_fetched < max_size:
            variables = {
                "filters": filters,
                "first": min(batch_size, max_size - total_fetched),
                "orderBy": "modified",
                "orderMode": "desc",
            }
            if after:
                variables["after"] = after
            self.helper.connector_logger.info(
                f"[DEBUG] Fetching batch {batch_num}{collection_str}: after={after}, batch_size={variables['first']}, total_fetched={total_fetched}"
            )
            try:
                result = self.helper.api.query(self.INDICATOR_QUERY, variables)
                data = result["data"]["indicators"]
                edges = data["edges"]
                if not edges:
                    self.helper.connector_logger.info(
                        f"[DEBUG] Batch {batch_num}{collection_str}: No more edges returned, stopping."
                    )
                    break
                for edge in edges:
                    indicators.append(edge["node"])
                    total_fetched += 1
                    if total_fetched >= max_size:
                        break
                page_info = data.get("pageInfo", {})
                after = page_info.get("endCursor")
                has_next_page = page_info.get("hasNextPage", False)
                self.helper.connector_logger.info(
                    f"[DEBUG] Batch {batch_num}{collection_str}: Retrieved {len(edges)} indicators, after={after}, has_next_page={has_next_page}"
                )
                batch_num += 1
                # Stop if there are no more results
                if not has_next_page or not after or len(edges) == 0:
                    self.helper.connector_logger.info(
                        f"[DEBUG] Batch {batch_num-1}{collection_str}: No more pages, stopping."
                    )
                    break
            except Exception as e:
                self.helper.connector_logger.error(
                    "GraphQL query failed",
                    {"error": str(e), "variables": variables},
                )
                break
        self.helper.connector_logger.info(
            f"Fetched {len(indicators)} indicators{collection_str}"
        )
        return indicators

    def run(self) -> None:
        import signal

        def handle_sigint(signum, frame):
            self.helper.connector_logger.info(
                "Received interrupt signal, shutting down gracefully."
            )
            sys.exit(0)

        signal.signal(signal.SIGINT, handle_sigint)

        while True:
            start_time = time.time()
            try:
                state = self.helper.get_state() or {}
                opencti_all_indicators = []

                now_iso = (
                    datetime.now(timezone.utc) + timedelta(minutes=10)
                ).isoformat()

                validity_filter = {
                    "key": "valid_until",
                    "operator": "gt",
                    "values": [now_iso],
                    "mode": "or",
                }

                # Prepare a mapping of collection to its rank (order in config)
                collection_rank = {
                    col: i for i, col in enumerate(self.config.taxii_collections)
                }

                # Get OpenCTI indicators
                for collection in self.config.taxii_collections:
                    if collection not in state:
                        state[collection] = {}
                    query = """
                        query TaxiiCollections($id: String!) {
                            taxiiCollection(id: $id) {
                                filters
                            }
                        }
                    """
                    try:
                        result = self.helper.api.query(query, {"id": collection})
                    except ValueError as ve:
                        # Check for FORBIDDEN_ACCESS error
                        if (
                            isinstance(ve.args[0], dict)
                            and ve.args[0].get("name") == "FORBIDDEN_ACCESS"
                        ):
                            self.helper.connector_logger.error(
                                "FORBIDDEN_ACCESS: The connector user does not have the required 'Manage data sharing' capability. Please ensure the user has this permission in OpenCTI.",
                                {"error": ve.args[0]},
                            )
                            raise
                        else:
                            self.helper.connector_logger.error(
                                "ValueError during TAXII collection query",
                                {"error": str(ve)},
                            )
                            raise
                    taxii_collection = result["data"].get("taxiiCollection")
                    if taxii_collection is not None and "filters" in taxii_collection:
                        filters = taxii_collection["filters"]
                        filters = json.loads(filters)
                        filters["filters"].append(validity_filter)
                        opencti_indicators = self.fetch_indicators_batched(
                            filters, collection_name=collection
                        )
                        self.helper.connector_logger.info(
                            f"Fetched {len(opencti_indicators)} indicators from collection '{collection}'"
                        )
                        if opencti_indicators:
                            try:
                                first_indicator = json.loads(
                                    opencti_indicators[0]["toStix"]
                                )
                                state[collection]["last_timestamp"] = (
                                    first_indicator.get("modified")
                                )
                            except Exception as e:
                                self.helper.connector_logger.warning(
                                    f"[STATE] Could not extract timestamp from first indicator: {e}"
                                )
                        state[collection]["last_count"] = len(opencti_indicators)
                        opencti_indicators = [
                            {
                                **json.loads(opencti_indicator["toStix"]),
                                "_collection": collection,
                                "_collection_rank": collection_rank[collection],
                            }
                            for opencti_indicator in opencti_indicators
                        ]
                        opencti_all_indicators.extend(opencti_indicators)
                    else:
                        self.helper.connector_logger.error(
                            "TAXII collection not found or has no filters",
                            {"id": collection},
                        )

                self.helper.log_info(
                    f"Found {len(opencti_all_indicators)} indicators in TAXII collections"
                )

                # ...existing code...

            except Exception as e:
                self.helper.connector_logger.error(
                    "An error occurred during the run", {"error": str(e)}
                )
            # Adjust sleep to maintain accurate interval
            elapsed = time.time() - start_time
            sleep_time = max(0, self.config.interval - elapsed)
            if sleep_time > 0:
                time.sleep(sleep_time)
